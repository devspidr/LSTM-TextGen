{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e7b638-aaa6-4dac-8198-716ee70e1873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn.utils import clip_grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa3a2bb-8e30-46c2-b00a-aacd2e6580e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        # Maps words to indices\n",
    "        self.word2idx = {}\n",
    "        # Maps indices back to words\n",
    "        self.idx2word = {}\n",
    "        # Keeps track of the next available index\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # Add the word if it's not already in the dictionary\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx     # Assign current index to word\n",
    "            self.idx2word[self.idx] = word     # Store word at that index\n",
    "            self.idx += 1                      # Increment index for next word\n",
    "            \n",
    "    def __len__(self):\n",
    "        # Return total number of unique words in the dictionary\n",
    "        return len(self.word2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43734aa6-78b1-41e2-a9fb-65f0f89ec61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcess(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Create a Dictionary instance to map each unique word to an index\n",
    "        self.dictionary = Dictionary()\n",
    "\n",
    "    def get_data(self, path, batch_size=20):\n",
    "        # ---- First Pass: Build the vocabulary ----\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0  # Keeps track of total number of words (tokens) in the file\n",
    "            for line in f:\n",
    "                # Split each line into words and add a special <eos> token for end of sentence\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)  # Count words in this line\n",
    "                # Add each word to the dictionary (assign index if not already added)\n",
    "                for word in words: \n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # ---- Create a tensor to store all tokens as indices ----\n",
    "        # We now know the total number of tokens, so create a LongTensor of that size\n",
    "        rep_tensor = torch.LongTensor(tokens)\n",
    "        index = 0  # Pointer to current position in rep_tensor\n",
    "\n",
    "        # ---- Second Pass: Convert words to their numeric indices ----\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                # Again split words and add end-of-sentence token\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    # Map each word to its index using the dictionary and store it in the tensor\n",
    "                    rep_tensor[index] = self.dictionary.word2idx[word]\n",
    "                    index += 1  # Move to next position\n",
    "\n",
    "        # ---- Prepare batches ----\n",
    "        # Total number of complete batches we can make (ignore leftover tokens)\n",
    "        num_batches = rep_tensor.shape[0] // batch_size\n",
    "        # Trim off any extra tokens that don't fit into a complete batch\n",
    "        rep_tensor = rep_tensor[:num_batches * batch_size]\n",
    "        # Reshape the tensor into (batch_size, num_batches_per_batch)\n",
    "        # Each column represents a time step, and each row a batch sample\n",
    "        rep_tensor = rep_tensor.view(batch_size, -1)\n",
    "\n",
    "        # Return the processed data tensor\n",
    "        return rep_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0447a4e-ca37-47ad-84f3-114ea2411100",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300      # Each word will be converted into a 300-dimensional vector (richer word embedding)\n",
    "hidden_size = 1024    # Number of units (neurons) in each LSTM layer, controls the capacity of the model\n",
    "num_layers = 2        # Number of stacked LSTM layers (more layers to learn complex patterns)\n",
    "num_epochs = 40       # How many times the model will see the entire dataset during training (longer training)\n",
    "batch_size = 32       # Number of sequences (samples) processed together in one training step (larger batch for stability)\n",
    "timesteps = 50        # Number of words (time steps) in each sequence input to the LSTM (longer context)\n",
    "learning_rate = 0.001 # Speed at which the model will update its weights (slower learning rate for smoother training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7b0de4-ca86-40e7-ad60-b2dd378aa834",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = TextProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "317b3744-8e36-4964-8cbf-706b8a60ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_tensor = corpus.get_data('alice.txt', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d08a8c-cca9-44b3-8daf-2d19d58a5206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 927])\n"
     ]
    }
   ],
   "source": [
    "#rep_tensor is the tensor that contains the index of all the words. Each row contains 1659 words by default \n",
    "print(rep_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c62a3f-5865-46d7-a883-d3faab761ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5290\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of unique words in the text file\n",
    "vocab_size = len(corpus.dictionary)  \n",
    "\n",
    "# Print the vocabulary size (how many distinct words are in alice.txt)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71daa2d5-3930-48ad-a08b-52873f59eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# Calculate how many complete batches of sequences we can get\n",
    "# rep_tensor.shape[1] -> total number of tokens per batch row\n",
    "# timesteps -> number of words (time steps) in each sequence for the LSTM\n",
    "num_batches = rep_tensor.shape[1] // timesteps\n",
    "\n",
    "# Print the total number of batches we can form\n",
    "print(num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df747475-9432-42ce-82cb-51d61f18f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        # Embedding layer: converts word indices into dense vectors of size embed_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        # LSTM layer: processes the sequence of embeddings\n",
    "        # batch_first=True -> input/output has shape (batch_size, timesteps, features)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        # Linear layer: maps the LSTM's hidden output to vocabulary size (for word prediction)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        # x: input word indices of shape (batch_size, timesteps)\n",
    "        # h: previous hidden and cell states (h0, c0)\n",
    "\n",
    "        # Convert word indices to embeddings\n",
    "        x = self.embed(x)\n",
    "\n",
    "        # Pass embeddings through LSTM; get output sequence and new states\n",
    "        out, (h, c) = self.lstm(x, h)\n",
    "\n",
    "        # Reshape output so that each time step in the batch is treated as a separate sample\n",
    "        # Shape: (batch_size * timesteps, hidden_size)\n",
    "        out = out.reshape(out.size(0) * out.size(1), out.size(2))\n",
    "\n",
    "        # Map LSTM outputs to vocabulary scores (logits for each word in the vocab)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        # Return predicted scores for all words + new hidden and cell states\n",
    "        return out, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81944186-4d9a-490a-acf5-1881756a5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the TextGenerator model\n",
    "# Pass vocabulary size, embedding dimension, hidden layer size, and number of LSTM layers\n",
    "model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf171ce4-ba59-4e57-af91-4dc81f775751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function as Cross Entropy Loss\n",
    "# This is commonly used for multi-class classification tasks like predicting the next word\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer as Adam, which updates model parameters during training\n",
    "# Uses the specified learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40d4ebc2-5c61-44aa-b293-9e4a716af26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detach(states):\n",
    "    \"\"\"\n",
    "If we have a tensor z,'z.detach()' returns a tensor that shares the same storage\n",
    "as 'z', but with the computation history forgotten. It doesn't know anything\n",
    "about how it was computed. In other words, we have broken the tensor z away from its past history\n",
    "Here, we want to perform truncated Backpropagation\n",
    "TBPTT splits the 1,000-long sequence into 50 sequences (say) each of length 20 and treats each sequence of length 20 as \n",
    "a separate training case. This is a sensible approach that can work well in practice, but it is blind to temporal \n",
    "dependencies that span more than 20 timesteps.\n",
    "    \"\"\"\n",
    "    return [state.detach() for state in states] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df89bc3c-4177-475b-9a9e-181ecfb23f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOUNDAR\\AppData\\Local\\Temp\\ipykernel_14100\\2608739910.py:26: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  clip_grad_norm(model.parameters(), 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 8.5764\n",
      "Epoch [2/40], Loss: 6.6756\n",
      "Epoch [3/40], Loss: 6.3445\n",
      "Epoch [4/40], Loss: 6.1226\n",
      "Epoch [5/40], Loss: 5.8413\n",
      "Epoch [6/40], Loss: 5.5317\n",
      "Epoch [7/40], Loss: 5.2067\n",
      "Epoch [8/40], Loss: 4.8968\n",
      "Epoch [9/40], Loss: 4.7172\n",
      "Epoch [10/40], Loss: 4.4067\n",
      "Epoch [11/40], Loss: 4.0655\n",
      "Epoch [12/40], Loss: 3.7729\n",
      "Epoch [13/40], Loss: 3.4590\n",
      "Epoch [14/40], Loss: 3.2306\n",
      "Epoch [15/40], Loss: 2.9017\n",
      "Epoch [16/40], Loss: 2.5615\n",
      "Epoch [17/40], Loss: 2.2984\n",
      "Epoch [18/40], Loss: 2.0699\n",
      "Epoch [19/40], Loss: 1.8987\n",
      "Epoch [20/40], Loss: 1.6491\n",
      "Epoch [21/40], Loss: 1.3611\n",
      "Epoch [22/40], Loss: 1.1665\n",
      "Epoch [23/40], Loss: 0.9983\n",
      "Epoch [24/40], Loss: 0.7911\n",
      "Epoch [25/40], Loss: 0.6174\n",
      "Epoch [26/40], Loss: 0.5008\n",
      "Epoch [27/40], Loss: 0.3859\n",
      "Epoch [28/40], Loss: 0.2998\n",
      "Epoch [29/40], Loss: 0.2144\n",
      "Epoch [30/40], Loss: 0.1576\n",
      "Epoch [31/40], Loss: 0.1210\n",
      "Epoch [32/40], Loss: 0.1030\n",
      "Epoch [33/40], Loss: 0.0756\n",
      "Epoch [34/40], Loss: 0.0645\n",
      "Epoch [35/40], Loss: 0.0568\n",
      "Epoch [36/40], Loss: 0.0536\n",
      "Epoch [37/40], Loss: 0.0501\n",
      "Epoch [38/40], Loss: 0.0480\n",
      "Epoch [39/40], Loss: 0.0459\n",
      "Epoch [40/40], Loss: 0.0444\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Initialize hidden and cell states for the LSTM with zeros at the start of each epoch\n",
    "    states = (torch.zeros(num_layers, batch_size, hidden_size),\n",
    "              torch.zeros(num_layers, batch_size, hidden_size))\n",
    "\n",
    "    # Loop over the data in chunks of 'timesteps' length\n",
    "    for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n",
    "        # Prepare input batch: sequences of length 'timesteps'\n",
    "        inputs = rep_tensor[:, i:i+timesteps]\n",
    "        # Prepare target batch: next words following inputs (shifted by 1)\n",
    "        targets = rep_tensor[:, (i+1):(i+1)+timesteps]\n",
    "        \n",
    "        # Forward pass: get model outputs and updated states\n",
    "        outputs, _ = model(inputs, states)\n",
    "        \n",
    "        # Compute loss comparing predicted outputs with true targets\n",
    "        # targets.reshape(-1) flattens targets to match outputs shape\n",
    "        loss = loss_fn(outputs, targets.reshape(-1))\n",
    "\n",
    "        # Zero out gradients from the previous step\n",
    "        model.zero_grad()\n",
    "        # Backpropagate the loss to compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping: limit gradient values between -0.5 and 0.5 to prevent exploding gradients\n",
    "        clip_grad_norm(model.parameters(), 0.5)\n",
    "        \n",
    "        # Update model parameters using optimizer\n",
    "        optimizer.step()\n",
    "              \n",
    "        step = (i + 1) // timesteps\n",
    "        # Print loss every 100 steps for monitoring training progress\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ab1c2a-8a88-4946-a0c1-48a00fda6d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5290])\n",
      "3006\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3582\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "512\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1927\n",
      "torch.Size([1, 5290])\n",
      "4025\n",
      "torch.Size([1, 5290])\n",
      "2156\n",
      "torch.Size([1, 5290])\n",
      "2939\n",
      "torch.Size([1, 5290])\n",
      "990\n",
      "torch.Size([1, 5290])\n",
      "3231\n",
      "torch.Size([1, 5290])\n",
      "144\n",
      "torch.Size([1, 5290])\n",
      "1386\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2647\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3244\n",
      "torch.Size([1, 5290])\n",
      "2326\n",
      "torch.Size([1, 5290])\n",
      "2138\n",
      "torch.Size([1, 5290])\n",
      "3769\n",
      "torch.Size([1, 5290])\n",
      "66\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "2032\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1234\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "439\n",
      "torch.Size([1, 5290])\n",
      "569\n",
      "torch.Size([1, 5290])\n",
      "2162\n",
      "torch.Size([1, 5290])\n",
      "4266\n",
      "torch.Size([1, 5290])\n",
      "248\n",
      "torch.Size([1, 5290])\n",
      "2359\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "635\n",
      "torch.Size([1, 5290])\n",
      "575\n",
      "torch.Size([1, 5290])\n",
      "4128\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "411\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1967\n",
      "torch.Size([1, 5290])\n",
      "632\n",
      "torch.Size([1, 5290])\n",
      "1205\n",
      "torch.Size([1, 5290])\n",
      "2738\n",
      "torch.Size([1, 5290])\n",
      "41\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "4795\n",
      "torch.Size([1, 5290])\n",
      "575\n",
      "torch.Size([1, 5290])\n",
      "238\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "3728\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "262\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "144\n",
      "torch.Size([1, 5290])\n",
      "24\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "2100\n",
      "torch.Size([1, 5290])\n",
      "172\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "1002\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "892\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "4307\n",
      "torch.Size([1, 5290])\n",
      "3545\n",
      "torch.Size([1, 5290])\n",
      "1311\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "2527\n",
      "torch.Size([1, 5290])\n",
      "1353\n",
      "torch.Size([1, 5290])\n",
      "2337\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1967\n",
      "torch.Size([1, 5290])\n",
      "607\n",
      "torch.Size([1, 5290])\n",
      "1434\n",
      "torch.Size([1, 5290])\n",
      "169\n",
      "torch.Size([1, 5290])\n",
      "236\n",
      "torch.Size([1, 5290])\n",
      "2024\n",
      "torch.Size([1, 5290])\n",
      "110\n",
      "torch.Size([1, 5290])\n",
      "3251\n",
      "torch.Size([1, 5290])\n",
      "1857\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "1652\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "892\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "970\n",
      "torch.Size([1, 5290])\n",
      "710\n",
      "torch.Size([1, 5290])\n",
      "4554\n",
      "Sampled [100/500] words and saved to results.txt\n",
      "torch.Size([1, 5290])\n",
      "930\n",
      "torch.Size([1, 5290])\n",
      "2162\n",
      "torch.Size([1, 5290])\n",
      "891\n",
      "torch.Size([1, 5290])\n",
      "668\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "194\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "852\n",
      "torch.Size([1, 5290])\n",
      "1194\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "1652\n",
      "torch.Size([1, 5290])\n",
      "1102\n",
      "torch.Size([1, 5290])\n",
      "268\n",
      "torch.Size([1, 5290])\n",
      "1217\n",
      "torch.Size([1, 5290])\n",
      "132\n",
      "torch.Size([1, 5290])\n",
      "748\n",
      "torch.Size([1, 5290])\n",
      "4981\n",
      "torch.Size([1, 5290])\n",
      "2394\n",
      "torch.Size([1, 5290])\n",
      "4495\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "812\n",
      "torch.Size([1, 5290])\n",
      "4002\n",
      "torch.Size([1, 5290])\n",
      "193\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "2898\n",
      "torch.Size([1, 5290])\n",
      "1342\n",
      "torch.Size([1, 5290])\n",
      "2117\n",
      "torch.Size([1, 5290])\n",
      "114\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2804\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1042\n",
      "torch.Size([1, 5290])\n",
      "57\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "84\n",
      "torch.Size([1, 5290])\n",
      "1185\n",
      "torch.Size([1, 5290])\n",
      "362\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "1735\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "1735\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "1735\n",
      "torch.Size([1, 5290])\n",
      "489\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "921\n",
      "torch.Size([1, 5290])\n",
      "663\n",
      "torch.Size([1, 5290])\n",
      "3285\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "668\n",
      "torch.Size([1, 5290])\n",
      "59\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3067\n",
      "torch.Size([1, 5290])\n",
      "1102\n",
      "torch.Size([1, 5290])\n",
      "156\n",
      "torch.Size([1, 5290])\n",
      "2894\n",
      "torch.Size([1, 5290])\n",
      "1899\n",
      "torch.Size([1, 5290])\n",
      "239\n",
      "torch.Size([1, 5290])\n",
      "1948\n",
      "torch.Size([1, 5290])\n",
      "2375\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "2285\n",
      "torch.Size([1, 5290])\n",
      "76\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "706\n",
      "torch.Size([1, 5290])\n",
      "415\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3201\n",
      "torch.Size([1, 5290])\n",
      "103\n",
      "torch.Size([1, 5290])\n",
      "372\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "2023\n",
      "torch.Size([1, 5290])\n",
      "57\n",
      "torch.Size([1, 5290])\n",
      "34\n",
      "torch.Size([1, 5290])\n",
      "203\n",
      "torch.Size([1, 5290])\n",
      "3708\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3153\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "542\n",
      "torch.Size([1, 5290])\n",
      "3561\n",
      "torch.Size([1, 5290])\n",
      "2368\n",
      "torch.Size([1, 5290])\n",
      "505\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3745\n",
      "Sampled [200/500] words and saved to results.txt\n",
      "torch.Size([1, 5290])\n",
      "2763\n",
      "torch.Size([1, 5290])\n",
      "627\n",
      "torch.Size([1, 5290])\n",
      "169\n",
      "torch.Size([1, 5290])\n",
      "1064\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5270\n",
      "torch.Size([1, 5290])\n",
      "249\n",
      "torch.Size([1, 5290])\n",
      "4954\n",
      "torch.Size([1, 5290])\n",
      "327\n",
      "torch.Size([1, 5290])\n",
      "73\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "1710\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3251\n",
      "torch.Size([1, 5290])\n",
      "675\n",
      "torch.Size([1, 5290])\n",
      "1918\n",
      "torch.Size([1, 5290])\n",
      "2314\n",
      "torch.Size([1, 5290])\n",
      "1644\n",
      "torch.Size([1, 5290])\n",
      "2910\n",
      "torch.Size([1, 5290])\n",
      "1235\n",
      "torch.Size([1, 5290])\n",
      "812\n",
      "torch.Size([1, 5290])\n",
      "2429\n",
      "torch.Size([1, 5290])\n",
      "2336\n",
      "torch.Size([1, 5290])\n",
      "174\n",
      "torch.Size([1, 5290])\n",
      "329\n",
      "torch.Size([1, 5290])\n",
      "4696\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "560\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "3794\n",
      "torch.Size([1, 5290])\n",
      "1939\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "102\n",
      "torch.Size([1, 5290])\n",
      "627\n",
      "torch.Size([1, 5290])\n",
      "169\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1927\n",
      "torch.Size([1, 5290])\n",
      "1366\n",
      "torch.Size([1, 5290])\n",
      "3523\n",
      "torch.Size([1, 5290])\n",
      "674\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "2898\n",
      "torch.Size([1, 5290])\n",
      "4544\n",
      "torch.Size([1, 5290])\n",
      "4696\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "439\n",
      "torch.Size([1, 5290])\n",
      "890\n",
      "torch.Size([1, 5290])\n",
      "1892\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "801\n",
      "torch.Size([1, 5290])\n",
      "721\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1967\n",
      "torch.Size([1, 5290])\n",
      "574\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "102\n",
      "torch.Size([1, 5290])\n",
      "1967\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1780\n",
      "torch.Size([1, 5290])\n",
      "1941\n",
      "torch.Size([1, 5290])\n",
      "18\n",
      "torch.Size([1, 5290])\n",
      "238\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1763\n",
      "torch.Size([1, 5290])\n",
      "1521\n",
      "torch.Size([1, 5290])\n",
      "3209\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1710\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "1937\n",
      "torch.Size([1, 5290])\n",
      "3204\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "265\n",
      "torch.Size([1, 5290])\n",
      "21\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "2032\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "1735\n",
      "torch.Size([1, 5290])\n",
      "98\n",
      "torch.Size([1, 5290])\n",
      "5022\n",
      "torch.Size([1, 5290])\n",
      "3863\n",
      "torch.Size([1, 5290])\n",
      "1305\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "95\n",
      "torch.Size([1, 5290])\n",
      "3076\n",
      "torch.Size([1, 5290])\n",
      "4770\n",
      "torch.Size([1, 5290])\n",
      "919\n",
      "torch.Size([1, 5290])\n",
      "3682\n",
      "torch.Size([1, 5290])\n",
      "675\n",
      "torch.Size([1, 5290])\n",
      "234\n",
      "Sampled [300/500] words and saved to results.txt\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "148\n",
      "torch.Size([1, 5290])\n",
      "988\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "706\n",
      "torch.Size([1, 5290])\n",
      "2851\n",
      "torch.Size([1, 5290])\n",
      "2316\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "328\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "411\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "4307\n",
      "torch.Size([1, 5290])\n",
      "1823\n",
      "torch.Size([1, 5290])\n",
      "1256\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "413\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3067\n",
      "torch.Size([1, 5290])\n",
      "3887\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5270\n",
      "torch.Size([1, 5290])\n",
      "1150\n",
      "torch.Size([1, 5290])\n",
      "1151\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "285\n",
      "torch.Size([1, 5290])\n",
      "87\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "1652\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1923\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "2527\n",
      "torch.Size([1, 5290])\n",
      "3024\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "1710\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "3244\n",
      "torch.Size([1, 5290])\n",
      "2898\n",
      "torch.Size([1, 5290])\n",
      "614\n",
      "torch.Size([1, 5290])\n",
      "172\n",
      "torch.Size([1, 5290])\n",
      "930\n",
      "torch.Size([1, 5290])\n",
      "362\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "1456\n",
      "torch.Size([1, 5290])\n",
      "186\n",
      "torch.Size([1, 5290])\n",
      "73\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "3237\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5270\n",
      "torch.Size([1, 5290])\n",
      "2915\n",
      "torch.Size([1, 5290])\n",
      "1366\n",
      "torch.Size([1, 5290])\n",
      "3523\n",
      "torch.Size([1, 5290])\n",
      "674\n",
      "torch.Size([1, 5290])\n",
      "15\n",
      "torch.Size([1, 5290])\n",
      "755\n",
      "torch.Size([1, 5290])\n",
      "1366\n",
      "torch.Size([1, 5290])\n",
      "990\n",
      "torch.Size([1, 5290])\n",
      "1081\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "1603\n",
      "torch.Size([1, 5290])\n",
      "1601\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "3728\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2365\n",
      "torch.Size([1, 5290])\n",
      "941\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "2032\n",
      "torch.Size([1, 5290])\n",
      "80\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1967\n",
      "torch.Size([1, 5290])\n",
      "4754\n",
      "torch.Size([1, 5290])\n",
      "830\n",
      "torch.Size([1, 5290])\n",
      "3936\n",
      "torch.Size([1, 5290])\n",
      "174\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "1780\n",
      "torch.Size([1, 5290])\n",
      "1753\n",
      "torch.Size([1, 5290])\n",
      "1284\n",
      "torch.Size([1, 5290])\n",
      "1205\n",
      "torch.Size([1, 5290])\n",
      "4084\n",
      "torch.Size([1, 5290])\n",
      "1234\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "129\n",
      "torch.Size([1, 5290])\n",
      "156\n",
      "torch.Size([1, 5290])\n",
      "2680\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "Sampled [400/500] words and saved to results.txt\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "940\n",
      "torch.Size([1, 5290])\n",
      "2067\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "3433\n",
      "torch.Size([1, 5290])\n",
      "5216\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2647\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "44\n",
      "torch.Size([1, 5290])\n",
      "3728\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "4731\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "1649\n",
      "torch.Size([1, 5290])\n",
      "594\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "194\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "2956\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "2647\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "2346\n",
      "torch.Size([1, 5290])\n",
      "1417\n",
      "torch.Size([1, 5290])\n",
      "162\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "7\n",
      "torch.Size([1, 5290])\n",
      "194\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "1170\n",
      "torch.Size([1, 5290])\n",
      "2907\n",
      "torch.Size([1, 5290])\n",
      "2321\n",
      "torch.Size([1, 5290])\n",
      "2915\n",
      "torch.Size([1, 5290])\n",
      "4968\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1927\n",
      "torch.Size([1, 5290])\n",
      "1250\n",
      "torch.Size([1, 5290])\n",
      "13\n",
      "torch.Size([1, 5290])\n",
      "2285\n",
      "torch.Size([1, 5290])\n",
      "144\n",
      "torch.Size([1, 5290])\n",
      "1386\n",
      "torch.Size([1, 5290])\n",
      "117\n",
      "torch.Size([1, 5290])\n",
      "1002\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "38\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1115\n",
      "torch.Size([1, 5290])\n",
      "2066\n",
      "torch.Size([1, 5290])\n",
      "27\n",
      "torch.Size([1, 5290])\n",
      "309\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "3067\n",
      "torch.Size([1, 5290])\n",
      "1185\n",
      "torch.Size([1, 5290])\n",
      "2409\n",
      "torch.Size([1, 5290])\n",
      "1735\n",
      "torch.Size([1, 5290])\n",
      "779\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "1054\n",
      "torch.Size([1, 5290])\n",
      "505\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "16\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "1927\n",
      "torch.Size([1, 5290])\n",
      "97\n",
      "torch.Size([1, 5290])\n",
      "169\n",
      "torch.Size([1, 5290])\n",
      "1402\n",
      "torch.Size([1, 5290])\n",
      "234\n",
      "torch.Size([1, 5290])\n",
      "265\n",
      "torch.Size([1, 5290])\n",
      "439\n",
      "torch.Size([1, 5290])\n",
      "3546\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "668\n",
      "torch.Size([1, 5290])\n",
      "59\n",
      "torch.Size([1, 5290])\n",
      "9\n",
      "torch.Size([1, 5290])\n",
      "186\n",
      "torch.Size([1, 5290])\n",
      "73\n",
      "torch.Size([1, 5290])\n",
      "20\n",
      "torch.Size([1, 5290])\n",
      "6\n",
      "torch.Size([1, 5290])\n",
      "1652\n",
      "torch.Size([1, 5290])\n",
      "1001\n",
      "torch.Size([1, 5290])\n",
      "169\n",
      "torch.Size([1, 5290])\n",
      "824\n",
      "torch.Size([1, 5290])\n",
      "164\n",
      "torch.Size([1, 5290])\n",
      "5\n",
      "torch.Size([1, 5290])\n",
      "940\n",
      "torch.Size([1, 5290])\n",
      "1119\n",
      "torch.Size([1, 5290])\n",
      "272\n",
      "torch.Size([1, 5290])\n",
      "3\n",
      "torch.Size([1, 5290])\n",
      "476\n",
      "torch.Size([1, 5290])\n",
      "362\n",
      "torch.Size([1, 5290])\n",
      "173\n",
      "torch.Size([1, 5290])\n",
      "1735\n",
      "Sampled [500/500] words and saved to results.txt\n"
     ]
    }
   ],
   "source": [
    "# Test the model and generate text without computing gradients\n",
    "with torch.no_grad():\n",
    "    # Open a file to save the generated text\n",
    "    with open('results.txt', 'w') as f:\n",
    "        # Initialize hidden and cell states with zeros (for batch size = 1)\n",
    "        state = (torch.zeros(num_layers, 1, hidden_size),\n",
    "                 torch.zeros(num_layers, 1, hidden_size))\n",
    "        \n",
    "        # Randomly pick one word index as the starting input, shape: (1,1)\n",
    "        input = torch.randint(0, vocab_size, (1,)).long().unsqueeze(1)\n",
    "\n",
    "        # Generate 500 words one by one\n",
    "        for i in range(500):\n",
    "            # Forward pass: get model output and updated state for the current input\n",
    "            output, _ = model(input, state)\n",
    "            print(output.shape)  # (batch_size*timesteps, vocab_size), here batch=1, timesteps=1 → (1, vocab_size)\n",
    "\n",
    "            # Convert logits to probabilities by applying exponential (softmax is usually better, but exp works here)\n",
    "            prob = output.exp()\n",
    "\n",
    "            # Sample a word index from the probability distribution\n",
    "            word_id = torch.multinomial(prob, num_samples=1).item()\n",
    "            print(word_id)  # Print sampled word id\n",
    "            \n",
    "            # Update the input tensor with the sampled word id for the next iteration\n",
    "            input.fill_(word_id)\n",
    "\n",
    "            # Convert the sampled word id back to the actual word\n",
    "            word = corpus.dictionary.idx2word[word_id]\n",
    "            # Replace <eos> token with newline for better readability\n",
    "            word = '\\n' if word == '<eos>' else word + ' '\n",
    "\n",
    "            # Write the generated word to the file\n",
    "            f.write(word)\n",
    "            \n",
    "            # Print progress every 100 words generated\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Sampled [{}/{}] words and saved to {}'.format(i + 1, 500, 'results.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2768a1a-2c92-4fc9-8957-131af62d7915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
